\documentclass[a4paper, oneside, final]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[british]{babel}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{verbatim}
\usepackage{listings}


\lstset{
  language=Haskell, 
  frame=tb, 
  basicstyle=\footnotesize
}


\renewcommand{\britishhyphenmins}{22} 

\let\fref\undefined
\let\Fref\undefined

\usepackage{graphicx}
\usepackage{amssymb}

\setcounter{secnumdepth}{1} % Sæt overskriftsnummereringsdybde. Disable = -1.
\setlength{\parskip}{0.25in}

\pagestyle{plain}

\title{Topics in Programming Languages}

\begin{document}

\maketitle

\section{Abstract}

After many false starts throughout the past twenty years, physical
laws are finally forcing parallel computers into the mainstream.  This
creates many challenges for programmers accustomed to sequential
programming, but also motivation for developing new techniques.
Functional parallel programming is an application of classical
functional programming techniques, such as higher-order functions and
purity, to the problem of parallelism.  In Haskell, the \textit{Par
  monad} (covered in detail in section \ref{sec:parmonad}) is an
abstract programming interface for doing parallel computing based on
write-once communication variables.  Unfortunately, the common
implementation of the Par monad is fundamentally based on running
multiple threads within a single operating system process, which means
that the program cannot take advantage of more than one physical
machine.  Eden (covered in detail in section \ref{sec:eden}) is an
implementation of a \textit{distributed heap} for Haskell, that makes
it possible to distribute a Haskell program across an entire network
of machines.  We present an implementation of the Par monad that makes
use of the distributed heap provided by Eden, and demonstrate how
unchanged programs can now run on cluster computers.

\section{Eden}
\label{sec:eden}

Eden is a parallel functional programming language which extends
Haskell with constructs for the definition and instantiation of
parallel processes. Eden has been designed for distributed-memory
machines, i.e. clusters, this means that it is based on 
message-passing. This paradigm is very suitable for functional
programming and, as it turns out, very suitable for the Par Monad
as well. 

As mentioned Eden uses the process abstraction to provide parallelism.
The two main functions are \texttt{process} and \texttt{\#}. The
\texttt{process} functions turns a regular function into a parallel
processes and \texttt{\#} instantiates the parallel process with the
given argument and returns its result. \newline 

\begin{lstlisting}
process :: ( Trans a , Trans b ) => (a -> b) -> Process a b
( # )   :: ( Trans a , Trans b ) => Process a b -> a -> b
\end{lstlisting}

These two functions are all you need to write parallel programs using
Eden. The example below shows a parallel implementation of the
Fibonacci sequence \newline

\begin{lstlisting}
fib :: Int -> Int
fib 0 = 1
fib 1 = 1
fib n = process fib # (n-1) + process fib # (n-2)
\end{lstlisting}

Eden also provides a variety of skeletons for parallel processing
tasks that makes it faster to write parallel programs. However, in
our case both the process abstraction and the skeletons are too high-
level for our need as we're mainly interested in the distributed
heap. Instead we use EDI, the Eden Implementation Language, to
implement the Par Monad.

\subsection{EDI}
\label{sub:edi}

At the EDI level of Eden we deal with channels. Each Eden channel
connects an outport of the sender process to an inport of the receiver
process. Each machine runs a process, consisting of multiple threads,
with a one-to-one relation between threads and outports. Each thread
of a process evaluates some expression to normal form and sends the
result via its outport. In the type-system a channel is represented as
\texttt{ChanName} with three integers used to identify the inport
connecting a channel with a process. \newline

\begin{lstlisting}
data ChanName' a = Chan Int# Int# Int#
data Mode = Connect | Stream | Data | Instantiate Int

createC :: IO ( ChanName' a, a ) 
connectToPort :: ChanName' a -> IO ()
sendData :: Mode -> a -> IO ()
\end{lstlisting}

The function \texttt{createC} creates a primitive imput channel and a
handle to access the data received via this channel.
\texttt{connectToPort} connects the outport of the thread executing
the function call to a given channel i.e. the corresponding inport.
When using \texttt{sendData} you pass a mode as well as the data to be
transmitted. The \texttt{Connect} \texttt{Mode} is initially sent to
connect the outport to the corresponding inport. the \texttt{Data
Mode} is used to send a single value whereas \texttt{Stream} is used
to send the values of a data stream. The \texttt{Instantiate i} message
is sent to start a remote process on PE i.

Retrieving data is done implicitly by the runtime system which writes
data received via an inport directly into a placeholder in the heap
hence there is no primitive for reading data.

When the reading placeholder is identified as garbage, the process
holding the writing end can be terminated.

This is what you need to know to understand the Par Monad
implementation. For more information about Eden please refer
to ``Eden - Parallel Functional Programming with Haskell''\cite{eden}

\section{Par Monad}
\label{sec:parmonad}

The Par Monad was originally described in the paper ``A monad for deterministic parallelism''\cite{parmonad}. As the name suggests it is a monad for specifying pure parallel computations. It is especially well suited for dataflow networks. The purpose of this section is to make the reader comfortable with the Par Monad such that the next section will be understandable.

Given a computation in the Par Monad you can execute it concurrently with the current computation using the \texttt{fork} function. Computations in the \texttt{Par} monad can be extracted using the \texttt{runPar} function. \newline

\begin{lstlisting}
fork :: Par () -> Par ()
runPar :: Par a -> a
\end{lstlisting}

The astute reader may notice that \texttt{fork} and \texttt{runPar} aren't very useful by themselves as you would never be able to read the values produced by the parallel computations. A way to communicate results from the child to the parent process is necessary; for this the Par monad uses a communication abstraction they call IVars. \texttt{IVar}'s also act as the entry point to the Par Monad. \newline

\begin{lstlisting}
data IVar a 

new :: Par (IVar a)
get :: IVar a -> Par a
put :: NFData a => IVar a -> a -> Par ()
\end{lstlisting}

The \texttt{new} function creates a new IVar, \texttt{get} reads the
value stored in the IVar and \texttt{put} writes a value to the IVar.
If you invoke \texttt{get} on an empty \texttt{IVar} it will block
until a value is stored in the \texttt{IVar}. Readers familiar with
concurrent programming in Haskell may notice That this approach is
very similar to the use of \texttt{MVar} with the main difference that
IVars are write-once where \texttt{MVar}'s can be written multiple
times.

These five functions are that is needed to write parallel programs
using the Par Monad. The following listing shows a small example
program taken from \texttt{Control.Monad.Par} on
hackage\footnote{http://hackage.haskell.org/packages/archive/monad-
par/0.1.0.1/doc/html/Control-Monad-Par.html} \newline

\begin{lstlisting}[numbers=left, numberstyle=\tiny]
runPar $ do
   [a,b,c,d] <- sequence [new,new,new,new]
   fork $ do x <- get a; put b (x+1)
   fork $ do x <- get a; put c (x+2)
   fork $ do x <- get b
             y <- get c 
             put d (x+y)
   fork $ do put a (3 :: Int)
   get d
\end{lstlisting}

On line 1 four \texttt{IVar}'s are created. Lines 2-8 creates tasks
that read and write to different IVars in parallel. Line 9 reads the
value stored in the IVar bound to d and as such this is the value
returned by the entire program.The program is shown as a data-flow
diagram below.

\begin{lstlisting}
                            a
                           / \  
                          b   c
                           \ /
                            d
\end{lstlisting}

This should be sufficient to understand the purpose and usage of the
Par Monad.

\section{Implementing the Par Monad}

TODO: Mads

\section{Benchmarks}

We have performed some limited benchmarking of our implementation of
the Par backend, wherein we compare our performance to the default
implementation.  Tests were performed on
$\texttt{sci-0},\texttt{sci-1},\ldots,\texttt{sci-6}$, six computation
nodes available on the DIKU network, with each running a quad-core
2.40GHz Intel Xeon processor.  The \texttt{sci} systems are
virtualised servers, resulting in unknown network topography and
system load, which has resulted in some unpredictable variation in
performance, and while we re-ran some benchmarks multiple times to
obtain sensible results, there are still some inexplicable artifacts
left.  The benchmarks are thus not a very precise indication of the
ultimate performance potential of the EDI-based Par monad, but rather
a basic demonstration of the viability of the approach.  A serious
exploration of the implementation should involve benchmarks on
dedicated cluster computing systems.  Finally, note that it is not
possible to run the default Par monad implementation in a distributed
setting, hence it does not benefit from access to more than the four
CPUs available on a single machine.  The benchmark programs have been
taken from the \texttt{monad-par} package and were unmodified.
Specific parameters have been tuned to exhibit relatively long
runtimes and sensible chunking of parallel work, so the results should
not be dominated by startup overhead, or exhibit non-realistic
workloads.

Figure \ref{fig:blackscholes} shows results from an implementation of
the Black-Scholes equation, executed with parameters corresponding to
$20,000,000$ options divided into $1000$ blocks.  We observe
almost-linear scaling, but also significant overhead.  As the core of
the benchmark program is a naïve parallel map across a list of twenty
thousand elements (one process per element), this is not particularly
surprising, given that EDI threads are somewhat heavy compared to
lightweight GHC threads.

A probably best-case situation for our monad is shown in Figure
\ref{fig:parfib}.  The Parfib program computes a Fibonacci number
using the recursive formula $fib(n) = fib(n-1) + fib(n-2)$; running
the recursive calls in parallel, except when $n$ is less than a given
threshold.  In the benchmark, we compute $fib(50)$, with $n=30$ as the
threshold for switching to sequential computation, resulting in a
manageable (although still large) number of processes, each doing a
relatively work-intensive task (computing $fib(30)$).  As a
consequence, since the runtime is dominated by the actual work, the
increased overhead of EDI process creation and communication is not
very noticable, and we scale essentially linearly (except for a hiccup
at the very end, most likely due to virtualisation artifacts).

\begin{figure}
\caption{Black-Scholes}
\label{fig:blackscholes}
\includegraphics[width=7cm]{blackscholes-speedup.png}
\includegraphics[width=7cm]{blackscholes-runtimes.png}
\end{figure}


\begin{figure}
\caption{Parallel computation of Fibonacci number}
\label{parfib}
\includegraphics[width=7cm]{parfib_monad-speedup.png}
\includegraphics[width=7cm]{parfib_monad-runtimes.png}
\end{figure}

\section{Conclusion}

\bibliography{report}

\end{document}
